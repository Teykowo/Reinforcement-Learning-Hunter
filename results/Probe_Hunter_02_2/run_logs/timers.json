{
    "name": "root",
    "gauges": {
        "Probe.Policy.Entropy.mean": {
            "value": 1.2833338975906372,
            "min": 1.1373451948165894,
            "max": 1.967015266418457,
            "count": 400
        },
        "Probe.Policy.Entropy.sum": {
            "value": 6519.3359375,
            "min": 5222.76953125,
            "max": 11104.6416015625,
            "count": 400
        },
        "Probe.Environment.EpisodeLength.mean": {
            "value": 135.0625,
            "min": 35.56410256410256,
            "max": 378.2857142857143,
            "count": 400
        },
        "Probe.Environment.EpisodeLength.sum": {
            "value": 4322.0,
            "min": 1160.0,
            "max": 8561.0,
            "count": 400
        },
        "Probe.Step.mean": {
            "value": 1999997.0,
            "min": 4874.0,
            "max": 1999997.0,
            "count": 400
        },
        "Probe.Step.sum": {
            "value": 1999997.0,
            "min": 4874.0,
            "max": 1999997.0,
            "count": 400
        },
        "Probe.Policy.ExtrinsicValueEstimate.mean": {
            "value": 1.4557803869247437,
            "min": 0.4845048785209656,
            "max": 1.863074779510498,
            "count": 400
        },
        "Probe.Policy.ExtrinsicValueEstimate.sum": {
            "value": 87.3468246459961,
            "min": 25.12487030029297,
            "max": 205.4449005126953,
            "count": 400
        },
        "Probe.Environment.CumulativeReward.mean": {
            "value": 3.055095673305914,
            "min": 0.47950388081371786,
            "max": 3.3618509962525165,
            "count": 400
        },
        "Probe.Environment.CumulativeReward.sum": {
            "value": 97.76306154578924,
            "min": 8.467761144042015,
            "max": 320.6448561809957,
            "count": 400
        },
        "Probe.Policy.ExtrinsicReward.mean": {
            "value": 3.055095673305914,
            "min": 0.47950388081371786,
            "max": 3.3618509962525165,
            "count": 400
        },
        "Probe.Policy.ExtrinsicReward.sum": {
            "value": 97.76306154578924,
            "min": 8.467761144042015,
            "max": 320.6448561809957,
            "count": 400
        },
        "Probe.Losses.PolicyLoss.mean": {
            "value": 0.07148855801400109,
            "min": 0.053414574259477376,
            "max": 0.08292605220534219,
            "count": 400
        },
        "Probe.Losses.PolicyLoss.sum": {
            "value": 0.14297711602800217,
            "min": 0.10682914851895475,
            "max": 0.24317543382979545,
            "count": 400
        },
        "Probe.Losses.ValueLoss.mean": {
            "value": 0.15352690732106566,
            "min": 0.07801883244731773,
            "max": 0.4401862653903663,
            "count": 400
        },
        "Probe.Losses.ValueLoss.sum": {
            "value": 0.30705381464213133,
            "min": 0.15603766489463547,
            "max": 1.2117355441053708,
            "count": 400
        },
        "Probe.Policy.LearningRate.mean": {
            "value": 4.0232486592500046e-07,
            "min": 4.0232486592500046e-07,
            "max": 0.00029953110015630004,
            "count": 400
        },
        "Probe.Policy.LearningRate.sum": {
            "value": 8.046497318500009e-07,
            "min": 8.046497318500009e-07,
            "max": 0.0008943001518999499,
            "count": 400
        },
        "Probe.Policy.Epsilon.mean": {
            "value": 0.10013407500000002,
            "min": 0.10013407500000002,
            "max": 0.1998437,
            "count": 400
        },
        "Probe.Policy.Epsilon.sum": {
            "value": 0.20026815000000003,
            "min": 0.20026815000000003,
            "max": 0.59810005,
            "count": 400
        },
        "Probe.Policy.Beta.mean": {
            "value": 2.3394092500000023e-05,
            "min": 2.3394092500000023e-05,
            "max": 0.00998438563,
            "count": 400
        },
        "Probe.Policy.Beta.sum": {
            "value": 4.678818500000005e-05,
            "min": 4.678818500000005e-05,
            "max": 0.029810194994999997,
            "count": 400
        },
        "Probe.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 400
        },
        "Probe.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 400
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1658565759",
        "python_version": "3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Program Files\\Python39\\Scripts\\mlagents-learn config/ppo/Probe.yaml --run-id Probe_Hunter_02_2 --initialize-from Probe_Hunter_01",
        "mlagents_version": "0.29.0",
        "mlagents_envs_version": "0.29.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.11.0+cpu",
        "numpy_version": "1.19.2",
        "end_time_seconds": "1658571054"
    },
    "total": 5295.2350534,
    "count": 1,
    "self": 0.013328399999409157,
    "children": {
        "run_training.setup": {
            "total": 0.25902080000000005,
            "count": 1,
            "self": 0.25902080000000005
        },
        "TrainerController.start_learning": {
            "total": 5294.9627042,
            "count": 1,
            "self": 9.778278700066949,
            "children": {
                "TrainerController._reset_env": {
                    "total": 9.8020791,
                    "count": 1,
                    "self": 9.8020791
                },
                "TrainerController.advance": {
                    "total": 5275.221226799934,
                    "count": 266904,
                    "self": 4.714245199836114,
                    "children": {
                        "env_step": {
                            "total": 5270.506981600098,
                            "count": 266904,
                            "self": 4386.461390700256,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 879.4076157998617,
                                    "count": 266905,
                                    "self": 19.4921306999031,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 859.9154850999586,
                                            "count": 250107,
                                            "self": 143.0209906998466,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 716.894494400112,
                                                    "count": 250107,
                                                    "self": 716.894494400112
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 4.637975099980466,
                                    "count": 266904,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 5265.417552399915,
                                            "count": 266904,
                                            "is_parallel": true,
                                            "self": 1693.8974562000512,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.005745099999999503,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.0015583000000001235,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00418679999999938,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.00418679999999938
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 3571.5143510998637,
                                                    "count": 266904,
                                                    "is_parallel": true,
                                                    "self": 26.91930769969622,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 136.87704320000196,
                                                            "count": 266904,
                                                            "is_parallel": true,
                                                            "self": 136.87704320000196
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 3273.260544700083,
                                                            "count": 266904,
                                                            "is_parallel": true,
                                                            "self": 3273.260544700083
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 134.45745550008277,
                                                            "count": 266902,
                                                            "is_parallel": true,
                                                            "self": 63.072333700100074,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 71.3851217999827,
                                                                    "count": 533804,
                                                                    "is_parallel": true,
                                                                    "self": 71.3851217999827
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.199999991920777e-05,
                    "count": 1,
                    "self": 3.199999991920777e-05,
                    "children": {
                        "thread_root": {
                            "total": 0.0,
                            "count": 0,
                            "is_parallel": true,
                            "self": 0.0,
                            "children": {
                                "trainer_advance": {
                                    "total": 5280.2472616000305,
                                    "count": 243036,
                                    "is_parallel": true,
                                    "self": 16.62813720002032,
                                    "children": {
                                        "process_trajectory": {
                                            "total": 3619.4708137999964,
                                            "count": 243036,
                                            "is_parallel": true,
                                            "self": 3618.7242931999963,
                                            "children": {
                                                "RLTrainer._checkpoint": {
                                                    "total": 0.7465205999999398,
                                                    "count": 4,
                                                    "is_parallel": true,
                                                    "self": 0.7465205999999398
                                                }
                                            }
                                        },
                                        "_update_policy": {
                                            "total": 1644.1483106000137,
                                            "count": 952,
                                            "is_parallel": true,
                                            "self": 439.8902166000189,
                                            "children": {
                                                "TorchPPOOptimizer.update": {
                                                    "total": 1204.2580939999948,
                                                    "count": 45750,
                                                    "is_parallel": true,
                                                    "self": 1204.2580939999948
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.16108759999951872,
                    "count": 1,
                    "self": 0.002236199999060773,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.15885140000045794,
                            "count": 1,
                            "self": 0.15885140000045794
                        }
                    }
                }
            }
        }
    }
}